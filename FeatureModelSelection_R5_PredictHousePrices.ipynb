{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('kc_house_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date     price  bedrooms  bathrooms  sqft_living  \\\n",
       "0  7129300520  20141013T000000  221900.0         3       1.00         1180   \n",
       "1  6414100192  20141209T000000  538000.0         3       2.25         2570   \n",
       "2  5631500400  20150225T000000  180000.0         2       1.00          770   \n",
       "3  2487200875  20141209T000000  604000.0         4       3.00         1960   \n",
       "4  1954400510  20150218T000000  510000.0         3       2.00         1680   \n",
       "\n",
       "   sqft_lot  floors  waterfront  view     ...      grade  sqft_above  \\\n",
       "0      5650     1.0           0     0     ...          7        1180   \n",
       "1      7242     2.0           0     0     ...          7        2170   \n",
       "2     10000     1.0           0     0     ...          6         770   \n",
       "3      5000     1.0           0     0     ...          7        1050   \n",
       "4      8080     1.0           0     0     ...          8        1680   \n",
       "\n",
       "   sqft_basement  yr_built  yr_renovated  zipcode      lat     long  \\\n",
       "0              0      1955             0    98178  47.5112 -122.257   \n",
       "1            400      1951          1991    98125  47.7210 -122.319   \n",
       "2              0      1933             0    98028  47.7379 -122.233   \n",
       "3            910      1965             0    98136  47.5208 -122.393   \n",
       "4              0      1987             0    98074  47.6168 -122.045   \n",
       "\n",
       "   sqft_living15  sqft_lot15  \n",
       "0           1340        5650  \n",
       "1           1690        7639  \n",
       "2           2720        8062  \n",
       "3           1360        5000  \n",
       "4           1800        7503  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21613 entries, 0 to 21612\n",
      "Data columns (total 21 columns):\n",
      "id               21613 non-null int64\n",
      "date             21613 non-null object\n",
      "price            21613 non-null float64\n",
      "bedrooms         21613 non-null int64\n",
      "bathrooms        21613 non-null float64\n",
      "sqft_living      21613 non-null int64\n",
      "sqft_lot         21613 non-null int64\n",
      "floors           21613 non-null float64\n",
      "waterfront       21613 non-null int64\n",
      "view             21613 non-null int64\n",
      "condition        21613 non-null int64\n",
      "grade            21613 non-null int64\n",
      "sqft_above       21613 non-null int64\n",
      "sqft_basement    21613 non-null int64\n",
      "yr_built         21613 non-null int64\n",
      "yr_renovated     21613 non-null int64\n",
      "zipcode          21613 non-null int64\n",
      "lat              21613 non-null float64\n",
      "long             21613 non-null float64\n",
      "sqft_living15    21613 non-null int64\n",
      "sqft_lot15       21613 non-null int64\n",
      "dtypes: float64(5), int64(15), object(1)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "#all columns are integer or float. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['id','date', 'lat', 'long'] , axis=1)\n",
    "# droping id, date, latitude and longitude columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum().any()\n",
    "# checking if there is any column having null value .. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sqft_living  sqft_lot  sqft_above  sqft_basement  sqft_living15  sqft_lot15\n",
       "0         1180      5650        1180              0           1340        5650\n",
       "1         2570      7242        2170            400           1690        7639\n",
       "2          770     10000         770              0           2720        8062\n",
       "3         1960      5000        1050            910           1360        5000\n",
       "4         1680      8080        1680              0           1800        7503"
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:,['sqft_living', 'sqft_lot', 'sqft_above', 'sqft_basement', 'sqft_living15', 'sqft_lot15' ]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   yr_built  yr_renovated\n",
       "0      1955             0\n",
       "1      1951          1991\n",
       "2      1933             0\n",
       "3      1965             0\n",
       "4      1987             0"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:,['yr_built', 'yr_renovated']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.yr_renovated = df.yr_renovated.replace(0, -1)\n",
    "# need to scale this feature.. so all zeros will be -1 and all positive numbers will be scaled to 0 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zipcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>98178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>98028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>98136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>98074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   zipcode\n",
       "0    98178\n",
       "1    98125\n",
       "2    98028\n",
       "3    98136\n",
       "4    98074"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.zipcode.nunique())\n",
    "df.loc[:,['zipcode']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3     9824\n",
       "4     6882\n",
       "2     2760\n",
       "5     1601\n",
       "6      272\n",
       "1      199\n",
       "7       38\n",
       "8       13\n",
       "0       13\n",
       "9        6\n",
       "10       3\n",
       "11       1\n",
       "33       1\n",
       "Name: bedrooms, dtype: int64"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.bedrooms.nunique())\n",
    "df.bedrooms.value_counts()\n",
    "# bedrooms 11 and 33 seems to be incorrect valus.. so removing those rows from the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8757</th>\n",
       "      <td>520000.0</td>\n",
       "      <td>11</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3000</td>\n",
       "      <td>4960</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2400</td>\n",
       "      <td>600</td>\n",
       "      <td>1918</td>\n",
       "      <td>1999</td>\n",
       "      <td>98106</td>\n",
       "      <td>1420</td>\n",
       "      <td>4960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13314</th>\n",
       "      <td>1148000.0</td>\n",
       "      <td>10</td>\n",
       "      <td>5.25</td>\n",
       "      <td>4590</td>\n",
       "      <td>10920</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2500</td>\n",
       "      <td>2090</td>\n",
       "      <td>2008</td>\n",
       "      <td>-1</td>\n",
       "      <td>98004</td>\n",
       "      <td>2730</td>\n",
       "      <td>10400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15161</th>\n",
       "      <td>650000.0</td>\n",
       "      <td>10</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3610</td>\n",
       "      <td>11914</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>3010</td>\n",
       "      <td>600</td>\n",
       "      <td>1958</td>\n",
       "      <td>-1</td>\n",
       "      <td>98006</td>\n",
       "      <td>2040</td>\n",
       "      <td>11914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15870</th>\n",
       "      <td>640000.0</td>\n",
       "      <td>33</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1620</td>\n",
       "      <td>6000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1040</td>\n",
       "      <td>580</td>\n",
       "      <td>1947</td>\n",
       "      <td>-1</td>\n",
       "      <td>98103</td>\n",
       "      <td>1330</td>\n",
       "      <td>4700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19254</th>\n",
       "      <td>660000.0</td>\n",
       "      <td>10</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2920</td>\n",
       "      <td>3745</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1860</td>\n",
       "      <td>1060</td>\n",
       "      <td>1913</td>\n",
       "      <td>-1</td>\n",
       "      <td>98105</td>\n",
       "      <td>1810</td>\n",
       "      <td>3745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           price  bedrooms  bathrooms  sqft_living  sqft_lot  floors  \\\n",
       "8757    520000.0        11       3.00         3000      4960     2.0   \n",
       "13314  1148000.0        10       5.25         4590     10920     1.0   \n",
       "15161   650000.0        10       2.00         3610     11914     2.0   \n",
       "15870   640000.0        33       1.75         1620      6000     1.0   \n",
       "19254   660000.0        10       3.00         2920      3745     2.0   \n",
       "\n",
       "       waterfront  view  condition  grade  sqft_above  sqft_basement  \\\n",
       "8757            0     0          3      7        2400            600   \n",
       "13314           0     2          3      9        2500           2090   \n",
       "15161           0     0          4      7        3010            600   \n",
       "15870           0     0          5      7        1040            580   \n",
       "19254           0     0          4      7        1860           1060   \n",
       "\n",
       "       yr_built  yr_renovated  zipcode  sqft_living15  sqft_lot15  \n",
       "8757       1918          1999    98106           1420        4960  \n",
       "13314      2008            -1    98004           2730       10400  \n",
       "15161      1958            -1    98006           2040       11914  \n",
       "15870      1947            -1    98103           1330        4700  \n",
       "19254      1913            -1    98105           1810        3745  "
      ]
     },
     "execution_count": 526,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.bedrooms >= 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(index= [15870,8757,19254])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0    10679\n",
       "2.0     8239\n",
       "1.5     1910\n",
       "3.0      613\n",
       "2.5      161\n",
       "3.5        8\n",
       "Name: floors, dtype: int64"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.floors.nunique())\n",
    "df.floors.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    19486\n",
       "2      963\n",
       "3      510\n",
       "1      332\n",
       "4      319\n",
       "Name: view, dtype: int64"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.view.nunique())\n",
    "df.view.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3    14030\n",
       "4     5678\n",
       "5     1700\n",
       "2      172\n",
       "1       30\n",
       "Name: condition, dtype: int64"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.condition.nunique())\n",
    "df.condition.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7     8978\n",
       "8     6068\n",
       "9     2615\n",
       "6     2038\n",
       "10    1134\n",
       "11     399\n",
       "5      242\n",
       "12      90\n",
       "4       29\n",
       "13      13\n",
       "3        3\n",
       "1        1\n",
       "Name: grade, dtype: int64"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.grade.nunique())\n",
    "df.grade.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    21447\n",
       "1      163\n",
       "Name: waterfront, dtype: int64"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.waterfront.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_orig_train,X_orig_test, y_train, y_test = train_test_split(df.iloc[:,1:],df.iloc[:,[0]],test_size = .30,random_state = 34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15127, 16)\n",
      "(15127, 1)\n",
      "(6483, 16)\n",
      "(6483, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_orig_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_orig_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To get important  features using correlation matrix "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### corelation among independent features and getting list of features which are highly correlated to each other \n",
    "### correlation above .75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sqft_living', 'grade', 'sqft_above', 'sqft_living15']"
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using correlation matrix to indentify the correlated features and removing them from feature list. \n",
    "corr_matrix = df.corr().abs()\n",
    "lower = corr_matrix.where(np.tril(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "to_drop = [column for column in lower.columns if any(upper[column] > 0.75)]\n",
    "to_drop\n",
    "# looking at correlation matrix, below are the columns are which are highly correlated. so its better to remove\n",
    "# these features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### corelation amount dependent and independent features and getting list of features which are not correlated to depndent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dhirender.Jit\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['sqft_lot', 'condition', 'yr_built', 'zipcode', 'sqft_lot15']"
      ]
     },
     "execution_count": 536,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_drop1 = df_corr[df_corr.price.sort_values(ascending=False) < .10].price.index.tolist()\n",
    "# looking at target and varibales correlation, it seems that below features are not helping in \n",
    "to_drop1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "drop = to_drop + to_drop1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['price',\n",
       " 'bedrooms',\n",
       " 'bathrooms',\n",
       " 'floors',\n",
       " 'waterfront',\n",
       " 'view',\n",
       " 'sqft_basement',\n",
       " 'yr_renovated']"
      ]
     },
     "execution_count": 676,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation_imp_features = df.columns.tolist()\n",
    "correlation_imp_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test, y_train, y_test = train_test_split(df.iloc[:,1:],df.iloc[:,[0]],test_size = .30,random_state = 34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dhirender.Jit\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:334: DataConversionWarning: Data with input dtype int64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Dhirender.Jit\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Dhirender.Jit\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "minmaxscaler = preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "standardscaler = preprocessing.StandardScaler()\n",
    "\n",
    "X_train['yr_renovated'] = minmaxscaler.fit_transform(X_train.loc[:,['yr_renovated']])\n",
    "X_train['sqft_basement'] = standardscaler.fit_transform(X_train.loc[:,['sqft_basement']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.40588102 0.41412987 0.38144965 0.42248175 0.41166945 0.39757222\n",
      " 0.40317298 0.42441876 0.34450476 0.42318746]\n",
      "Average cross-validation score: 0.40\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "regr = linear_model.LinearRegression()\n",
    "scores = cross_val_score(regr, X_train,y_train, cv=10)\n",
    "print(\"Cross-validation scores: {}\".format(scores))\n",
    "print(\"Average cross-validation score: {:.2f}\".format(scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance of linear regression with above used features are very poor. Accuracy is of 40% only. Coefficient values are very high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 20323.12063112, 158425.15346857,  72668.70863631,\n",
       "        542275.17604505, 109770.12441913,  59278.71412197,\n",
       "        106265.6070285 ]])"
      ]
     },
     "execution_count": 678,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### standard scaling of data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dhirender.Jit\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Dhirender.Jit\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "C:\\Users\\Dhirender.Jit\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "standardscaler = preprocessing.StandardScaler()\n",
    "X_scaled_train = standardscaler.fit_transform(X_orig_train.loc[:,])\n",
    "X_scaled_test = standardscaler.transform(X_orig_test.loc[:,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To get the important features using Lasso "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting best hyperparameter for lasso "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyper Parameters: {'alpha': 1000}\n",
      "Accuracy: 0.6509539233004286\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import linear_model\n",
    "#making the instance\n",
    "lasso = linear_model.Lasso(random_state=1234)\n",
    "#Hyper Parameters Set\n",
    "params = {'alpha': [.1, 1, 5, 10, 50, 100, 500, 800, 1000,1500, 2000, 3000, 4000,  5000, 10000]}\n",
    "#Making models with hyper parameters sets\n",
    "model1 = GridSearchCV(lasso, param_grid=params, n_jobs=-1,cv=3)\n",
    "#Learning\n",
    "model1.fit(X_scaled_train,y_train)\n",
    "#The best hyper parameters set\n",
    "print(\"Best Hyper Parameters:\",model1.best_params_)\n",
    "prediction=model1.predict(X_scaled_test)\n",
    "#evaluation(Accuracy)\n",
    "print(\"Accuracy:\",model1.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best parameter alpha = 1000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lasso = linear_model.Lasso(alpha= 1000)\n",
    "lasso.fit(X_scaled_train, y_train)\n",
    "lasso_features = lasso.coef_.tolist()\n",
    "columnlist = X_orig_train.columns.tolist()\n",
    "lasso_imp = pd.DataFrame(lasso_features,columnlist,columns= ['importance'])\n",
    "lasso_imp_features = lasso_imp[lasso_imp.importance > 0].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6559566725207364\n",
      "0.6524973334997141\n"
     ]
    }
   ],
   "source": [
    "lasso_test_score= lasso.score(X_scaled_test, y_test)\n",
    "lasso_train_score= lasso.score(X_scaled_train, y_train)\n",
    "print(lasso_test_score)\n",
    "print(lasso_train_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -33218.87204386,   33320.28775158,  135893.18210372,\n",
       "             0.        ,   16090.53538186,   45809.37747594,\n",
       "         37669.45321426,   13222.64215524,  138398.37353321,\n",
       "             0.        ,    5642.06950314, -102293.94400329,\n",
       "          1756.31831426,       0.        ,   21069.90206592,\n",
       "        -12693.53383639])"
      ]
     },
     "execution_count": 840,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bathrooms',\n",
       " 'sqft_living',\n",
       " 'floors',\n",
       " 'waterfront',\n",
       " 'view',\n",
       " 'condition',\n",
       " 'grade',\n",
       " 'sqft_basement',\n",
       " 'yr_renovated',\n",
       " 'sqft_living15']"
      ]
     },
     "execution_count": 768,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_imp_features\n",
    "# list of important features from lasso model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This lasso regression model is not good again. Accracy has improved and now accuracy is 65%. coefficients values are still very high. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To get important features using randomforest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dhirender.Jit\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:740: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyper Parameters:\n",
      " {'criterion': 'mse', 'n_estimators': 130, 'n_jobs': -1, 'random_state': 123}\n",
      "Accuracy: 0.7980903606344774\n"
     ]
    }
   ],
   "source": [
    "#With Hyper Parameters Tuning\n",
    "#2-2,Randomforest\n",
    "#importing modules\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "#making the instance\n",
    "model=RandomForestRegressor()\n",
    "#hyper parameters set\n",
    "params = {'criterion':['mse'],\n",
    "          'n_estimators':[70,100,130, 150],\n",
    "          'random_state':[123],\n",
    "          'n_jobs':[-1]}\n",
    "#Making models with hyper parameters sets\n",
    "model1 = GridSearchCV(model, param_grid=params, n_jobs=-1,cv=3)\n",
    "#learning\n",
    "model1.fit(X_scaled_train,y_train)\n",
    "#The best hyper parameters set\n",
    "print(\"Best Hyper Parameters:\\n\",model1.best_params_)\n",
    "#Prediction\n",
    "prediction=model1.predict(X_scaled_test)\n",
    "#evaluation(Accuracy)\n",
    "print(\"Accuracy:\",model1.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best hyperparameters for random forest are criterion': 'mse', 'n_estimators': 130"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dhirender.Jit\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_estimators = 130, random_state = 42)\n",
    "rf.fit(X_scaled_train, y_train) \n",
    "rf_feature = rf.feature_importances_.tolist()\n",
    "columnlist = X_orig_train.columns.tolist()\n",
    "rf_imp = pd.DataFrame(rf_feature,columnlist,columns= ['importance'])\n",
    "rf_imp_features = rf_imp[rf_imp.importance != 0].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_test_score = rf.score(X_scaled_test, y_test)\n",
    "rf_train_score = rf.score(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'grade', 'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode', 'sqft_living15', 'sqft_lot15']\n",
      "0.9734221814317474\n",
      "0.824062931764382\n"
     ]
    }
   ],
   "source": [
    "print(rf_imp_features)\n",
    "print(rf_train_score)\n",
    "print(rf_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy has improved a lot in comparison with linear and lasso regression. Now accuracy is 82%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To get important features using SVR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dhirender.Jit\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\Dhirender.Jit\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyper Parameters:\n",
      " {'C': 12, 'kernel': 'linear'}\n",
      "Accuracy: 0.4145297003790064\n"
     ]
    }
   ],
   "source": [
    "#With Hyper Parameters Tuning\n",
    "#2-3,SVM\n",
    "#importing modules\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm\n",
    "#making the instance\n",
    "model=svm.SVR()\n",
    "#Hyper Parameters Set\n",
    "params = {'C': [6,7,8,9,10,11,12], \n",
    "          'kernel': ['linear','rbf']}\n",
    "#Making models with hyper parameters sets\n",
    "model1 = GridSearchCV(model, param_grid=params, n_jobs=-1)\n",
    "#Learning\n",
    "model1.fit(X_scaled_train,y_train)\n",
    "#The best hyper parameters set\n",
    "print(\"Best Hyper Parameters:\\n\",model1.best_params_)\n",
    "#Prediction\n",
    "prediction=model1.predict(X_scaled_test)\n",
    "#evaluation(Accuracy)\n",
    "print(\"Accuracy:\",model1.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR has given us very poor performance of 41% only. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA for feature reduction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 773,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "pca.fit(X_scaled_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.08830691e+00 1.98761356e+00 1.69312399e+00 1.34142554e+00\n",
      " 1.03538271e+00 9.04624456e-01 8.35152371e-01 6.75319893e-01\n",
      " 5.99314883e-01 5.09732262e-01 3.31637539e-01 3.06750900e-01\n",
      " 2.52140619e-01 2.38584203e-01 2.01947956e-01 3.41468308e-32]\n"
     ]
    }
   ],
   "source": [
    "#print(pca.components_) \n",
    "print(pca.explained_variance_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {},
   "outputs": [],
   "source": [
    "eig_vals = pca.explained_variance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative Variance Explained [ 31.79981584  44.22157935  54.80290476  63.18626012  69.65697426\n",
      "  75.31050335  80.52986061  84.75033092  88.49580132  91.68141735\n",
      "  93.75401494  95.67108133  97.24685602  98.73790871 100.\n",
      " 100.        ]\n"
     ]
    }
   ],
   "source": [
    "total = sum(pca.explained_variance_)\n",
    "var_exp = [( i /total ) * 100 for i in sorted(eig_vals, reverse=True)]\n",
    "cum_var_exp = np.cumsum(var_exp)   # array of size =  as many PC dimensions\n",
    "print(\"Cumulative Variance Explained\", cum_var_exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### taken first 14 features which explains 98% of variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(14)\n",
    "pca_train= pca.fit_transform(X_scaled_train)\n",
    "pca_test= pca.transform(X_scaled_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forest regressor used with pca features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dhirender.Jit\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:740: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyper Parameters:\n",
      " {'criterion': 'mse', 'n_estimators': 150, 'n_jobs': -1, 'random_state': 123}\n",
      "Accuracy: 0.7213497061681997\n"
     ]
    }
   ],
   "source": [
    "#With Hyper Parameters Tuning\n",
    "#2-2,Randomforest\n",
    "#importing modules\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "#making the instance\n",
    "model=RandomForestRegressor()\n",
    "#hyper parameters set\n",
    "params = {'criterion':['mse'],\n",
    "          'n_estimators':[70,100,130, 150],\n",
    "          'random_state':[123],\n",
    "          'n_jobs':[-1]}\n",
    "#Making models with hyper parameters sets\n",
    "model1 = GridSearchCV(model, param_grid=params, n_jobs=-1,cv=3)\n",
    "#learning\n",
    "model1.fit(pca_train,y_train)\n",
    "#The best hyper parameters set\n",
    "print(\"Best Hyper Parameters:\\n\",model1.best_params_)\n",
    "#Prediction\n",
    "prediction=model1.predict(pca_test)\n",
    "#evaluation(Accuracy)\n",
    "print(\"Accuracy:\",model1.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performace degrades when used forestregressor with PCA. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Polynomial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures \n",
    "poly = PolynomialFeatures(degree = 2) \n",
    "X_poly_train = poly.fit_transform(X_scaled_train) \n",
    "X_ploy_test=poly.transform(X_scaled_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear regression using polynomial features, degree = 2, performance is 75% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7645700367995766\n",
      "0.7513639936273713\n"
     ]
    }
   ],
   "source": [
    "regr2 = linear_model.LinearRegression()\n",
    "regr2.fit(X_poly_train, y_train) \n",
    "print(regr2.score(X_ploy_test, y_test))\n",
    "print(regr2.score(X_poly_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso regression using polynomial features, degree = 2, performance is 75% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7637646416139718\n",
      "0.7485818591181517\n"
     ]
    }
   ],
   "source": [
    "lasso2 = linear_model.Lasso(alpha= 1100)\n",
    "lasso2.fit(X_poly_train, y_train) \n",
    "print(lasso2.score(X_ploy_test, y_test))\n",
    "print(lasso2.score(X_poly_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dhirender.Jit\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7693840809746969\n",
      "0.9588378068496587\n"
     ]
    }
   ],
   "source": [
    "rf2 = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "rf2.fit(X_poly_train, y_train) \n",
    "print(rf2.score(X_ploy_test, y_test))\n",
    "print(rf2.score(X_poly_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Conclusion is that.. Random Forest Regressor with orginal scaled features is giving the optimal performance in comparison with linear, lasso, svr and randomforest.  Test accuracy is 82% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
